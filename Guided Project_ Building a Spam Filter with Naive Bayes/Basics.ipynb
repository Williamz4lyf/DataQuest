{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Building a Spam Filter with Naive Bayes\n",
    "In this project, our goal is to use the Naive Bayes algorithm to build a spam filter for SMS messages.\n",
    "\n",
    "To classify messages as spam or non-spam, the computer:\n",
    "- Learns how humans classify messages.\n",
    "- Uses that human knowledge to estimate probabilities for new messages — probabilities for spam and non-spam.\n",
    "- Classifies a new message based on these probability values — if the probability for spam is greater, then it classifies the message as spam. Otherwise, it classifies it as non-spam (if the two probability values are equal, then we may need a human to classify the message).\n",
    "\n",
    "Our first task will be to \"teach\" the computer how to classify messages. We'll use the multinomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages that are already classified by humans.\n",
    "\n",
    "We'll start by reading in the dataset.\n",
    "\n",
    "*Note that due to the nature of spam messages, the dataset contains content that may be offensive to some users.*"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "(5572, 2)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "  Label                                                SMS\n0   ham  Go until jurong point, crazy.. Available only ...\n1   ham                      Ok lar... Joking wif u oni...\n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3   ham  U dun say so early hor... U c already then say...\n4   ham  Nah I don't think he goes to usf, he lives aro...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>SMS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "ham     86.593683\nspam    13.406317\nName: Label, dtype: float64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts(normalize=True) * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our dataset contains 13.4% spam messages and 86.6% ham (non-spam) messages."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training and Test Set\n",
    "Before creating our spam filter, we need to design a way to test its efficacy. We'll do this by testing how good it is with classifying new messages. To conduct this test, we need to split the dataset into two categories:\n",
    "- A training set, which we'll use to \"train\" the computer to classify messages.\n",
    "- A test set, which we'll use to test how good the spam filter is with classifying new messages.\n",
    "\n",
    "Our train set will contain 80% of the dataset and the remainder 20% will be used for testing. The dataset has 5,572 messages, which means that:\n",
    "- The train set will have 4,458 messages (about 80% of the dataset).\n",
    "- The test set will have 1,114 messages (about 20% of the dataset).\n",
    "\n",
    "After training and testing, we'll be able to compare the algorithm classification with the classification done by a human, to confirm the efficacy of the spam filter. The success threshold for our spam filter is 80%, meaning that a successful spam filter will have an accuracy greater than 80%.\n",
    "\n",
    "We'll begin by creating a train and a test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Randomize the dataset\n",
    "df_random = df.sample(frac=1, random_state=1)\n",
    "\n",
    "# Calculate index for split\n",
    "train_index = round(len(df_random) * 0.8)\n",
    "\n",
    "# Train-Test Split\n",
    "train_set = df_random[:train_index].reset_index(drop=True)\n",
    "test_set = df_random[train_index:].reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's find the percentage of spam and ham in both the training and the test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "ham     86.54105\nspam    13.45895\nName: Label, dtype: float64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['Label'].value_counts(normalize=True) * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "ham     86.804309\nspam    13.195691\nName: Label, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Label'].value_counts(normalize=True) * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These value counts are identical to those in the original dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Letter Case and Punctuation\n",
    "Now that we've split our dataset into a train and test set. The next big step is to use the training set to teach the algorithm to classify new messages.\n",
    "\n",
    "In order to classify messages using the Naive Bayes algorithm, we'll use the following formula:\n",
    "- P(Spam|w1,w2,...,wn) ∝ P(Spam) * n∏i=1(P(wi|Spam))\n",
    "- P(Ham|w1,w2,...,wn) ∝ P(Ham) * n∏i=1(P(wi|Ham))\n",
    "\n",
    "To calculate P(wi|Spam) and P(wi|Ham) inside the formulas above, we need to use these equations:\n",
    "- P(wi|Spam) = Nwi|Spam + α / NSpam + α * NVocabulary\n",
    "- P(wi|Ham) = Nwi|Ham + α / NHam + α * NVocabulary\n",
    "\n",
    "Let's summarize what the terms in the equations above mean:\n",
    "- Nwi|Spam = the number of times the word wi occurs in spam messages\n",
    "- Nwi|Spam^C/Ham = the number of times the word wi occurs in non-spam messages\n",
    "- NSpam = total number of words in spam messages\n",
    "- NSpam^C/Ham = total number of words in non-spam messages\n",
    "- NVocabulary = total number of words in the vocabulary\n",
    "- α = 1 (α is a smoothing parameter)\n",
    "\n",
    "To calculate all these probabilities, we'll first need to perform a bit of data cleaning to bring the data in a format that will allow us to extract easily all the information we need. We need to use one-hot encoding (or dummy variables) to convert the categorical/ text values in the SMS column into integer values to make them easy for the algorithm to interpret. The categorical values become columns in the dataset used to count how many times the value occurs in an SMS record.\n",
    "\n",
    "All words in the vocabulary (i.e. categorical values in the columns) are in lower case. Upper case is ignored and all upper case values will be counted with their lower case counterparts. Punctuations are ignored.\n",
    "\n",
    "We'll begin the data cleaning process by removing the punctuation and bringing all the words to lower case."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "  Label                                                SMS\n0   ham                       yep  by the pretty sculpture\n1   ham      yes  princess  are you going to make me moan \n2   ham                         welp apparently he retired\n3   ham                                            havent \n4   ham  i forgot 2 ask ü all smth   there s a card on ...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>SMS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>yep  by the pretty sculpture</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>yes  princess  are you going to make me moan</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ham</td>\n      <td>welp apparently he retired</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>havent</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['SMS'] = train_set['SMS'].str.replace('\\W', ' ', regex=True).str.lower()\n",
    "train_set.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "  Label                                                SMS\n0   ham          later i guess  i needa do mcat study too \n1   ham             but i haf enuff space got like 4 mb   \n2  spam  had your mobile 10 mths  update to latest oran...\n3   ham  all sounds good  fingers   makes it difficult ...\n4   ham  all done  all handed in  don t know if mega sh...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>SMS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>later i guess  i needa do mcat study too</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>but i haf enuff space got like 4 mb</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>had your mobile 10 mths  update to latest oran...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>all sounds good  fingers   makes it difficult ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>all done  all handed in  don t know if mega sh...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['SMS'] = test_set['SMS'].str.replace('\\W', ' ', regex=True).str.lower()\n",
    "test_set.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating the Vocabulary\n",
    "We'll now create a list that contains all the unique words that occur in the messages of our training set (the vocabulary)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "  Label                                                SMS\n0   ham                  [yep, by, the, pretty, sculpture]\n1   ham  [yes, princess, are, you, going, to, make, me,...\n2   ham                    [welp, apparently, he, retired]\n3   ham                                           [havent]\n4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>SMS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>[yep, by, the, pretty, sculpture]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>[yes, princess, are, you, going, to, make, me,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ham</td>\n      <td>[welp, apparently, he, retired]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>[havent]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['SMS'] = train_set['SMS'].str.split()\n",
    "train_set.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "72427"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = list()\n",
    "for list_item in train_set['SMS']:\n",
    "    for item in list_item:\n",
    "        vocabulary.append(item)\n",
    "\n",
    "len(vocabulary)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "7783"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = list(set(vocabulary))\n",
    "len(vocabulary)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The Final Training Set\n",
    "We'll create a dictionary to count the occurrences of unique values in the vocabulary across the train set, then convert the dictionary to a dataframe.\n",
    "\n",
    "We'll start by initializing a dictionary where each key is a unique word (a string) from the vocabulary, and each value is a list of the length of training set, and where each element in the list is a 0.\n",
    "\n",
    "We'll then loop over the SMS column in the train set and using a nested loop, we'll increment the word count for each word in each sms."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(train_set['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(train_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll now transform the dictionary into a dataframe and join that dataframe to the train set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "  Label                                                SMS  08709501522  \\\n0   ham                  [yep, by, the, pretty, sculpture]            0   \n1   ham  [yes, princess, are, you, going, to, make, me,...            0   \n2   ham                    [welp, apparently, he, retired]            0   \n3   ham                                           [havent]            0   \n4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...            0   \n\n   received  book  shorter  adult  eshxxxxxxxxxxx  odalebeku  wales  ...  \\\n0         0     0        0      0               0          0      0  ...   \n1         0     0        0      0               0          0      0  ...   \n2         0     0        0      0               0          0      0  ...   \n3         0     0        0      0               0          0      0  ...   \n4         0     0        0      0               0          0      0  ...   \n\n   overa  audrey  regalportfolio  minute  food  countin  colin  09064015307  \\\n0      0       0               0       0     0        0      0            0   \n1      0       0               0       0     0        0      0            0   \n2      0       0               0       0     0        0      0            0   \n3      0       0               0       0     0        0      0            0   \n4      0       0               0       0     0        0      0            0   \n\n   peace  hmv  \n0      0    0  \n1      0    0  \n2      0    0  \n3      0    0  \n4      0    0  \n\n[5 rows x 7785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>SMS</th>\n      <th>08709501522</th>\n      <th>received</th>\n      <th>book</th>\n      <th>shorter</th>\n      <th>adult</th>\n      <th>eshxxxxxxxxxxx</th>\n      <th>odalebeku</th>\n      <th>wales</th>\n      <th>...</th>\n      <th>overa</th>\n      <th>audrey</th>\n      <th>regalportfolio</th>\n      <th>minute</th>\n      <th>food</th>\n      <th>countin</th>\n      <th>colin</th>\n      <th>09064015307</th>\n      <th>peace</th>\n      <th>hmv</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>[yep, by, the, pretty, sculpture]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>[yes, princess, are, you, going, to, make, me,...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ham</td>\n      <td>[welp, apparently, he, retired]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>[havent]</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 7785 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = pd.DataFrame(word_counts_per_sms)\n",
    "train_df = pd.concat([train_set, word_count], axis=1)\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculating Constants First\n",
    "Now that we're done with data cleaning and have a training set to work with, we can begin creating the spam filter. The Naive Bayes algorithm will need to know the probability values of the two equations below to be able to classify new messages:\n",
    "- P(Spam|w1,w2,...,wn) ∝ P(Spam) * n∏i=1(P(wi|Spam))\n",
    "- P(Ham|w1,w2,...,wn) ∝ P(Ham) * n∏i=1(P(wi|Ham))\n",
    "\n",
    "To calculate P(wi|Spam) and P(wi|Ham) inside the formulas above, we need to use these equations:\n",
    "- P(wi|Spam) = Nwi|Spam + α / NSpam + α * NVocabulary\n",
    "- P(wi|Ham) = Nwi|Ham + α / NHam + α * NVocabulary\n",
    "\n",
    "We'll start by calculating P(Spam), P(Ham), NSpam, NHam, NVocabulary.\n",
    "NSpam is the total number of words in all spam messages while NHam is the total number of words in all Ham (non-spam) messages. We'll also use Laplace smoothing and set α = 1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8654104979811574 0.13458950201884254\n"
     ]
    }
   ],
   "source": [
    "alpha = 1\n",
    "\n",
    "p_ham = train_df['Label'].value_counts(normalize=True).loc['ham']\n",
    "p_spam = train_df['Label'].value_counts(normalize=True).loc['spam']\n",
    "print(p_ham, p_spam)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "ham_msg = train_df.loc[train_df['Label'] == 'ham']\n",
    "spam_msg = train_df.loc[train_df['Label'] == 'spam']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57237 15190 7783\n"
     ]
    }
   ],
   "source": [
    "n_ham = 0\n",
    "for list_item in ham_msg['SMS']:\n",
    "    for item in list_item:\n",
    "        n_ham += 1\n",
    "\n",
    "n_spam = 0\n",
    "for list_item in spam_msg['SMS']:\n",
    "    for item in list_item:\n",
    "        n_spam += 1\n",
    "\n",
    "n_vocabulary = len(vocabulary)\n",
    "print(n_ham, n_spam, n_vocabulary)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculating Parameters\n",
    "The values P(Spam), P(Ham), NSpam, NHam, NVocabulary are constants in our equations for every new message. However, P(wi|Spam) and P(wi|Ham) will vary depending on the individual words. The probability values that P(wi|Spam) and P(wi|Ham) will take are called parameters.\n",
    "\n",
    "We'll initialize two dictionaries, where each key-value pair is a unique word (from our vocabulary) represented as a string, and the value is 0. We'll need one dictionary to store the parameters for P(wi|Spam), and the other for P(wi|Ham)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "p_ham_words = {unique_word: 0 for unique_word in vocabulary}\n",
    "p_spam_words = {unique_word: 0 for unique_word in vocabulary}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's check one of the dictionaries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08709501522 0\n",
      "received 0\n",
      "book 0\n",
      "shorter 0\n",
      "adult 0\n"
     ]
    }
   ],
   "source": [
    "for idx, (k, v) in enumerate(p_ham_words.items()):\n",
    "    if idx == 5: break\n",
    "    print(k, v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we'll calculate the parameters for each word."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_msg[word].sum()\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + (alpha * n_vocabulary))\n",
    "    p_spam_words[word] = p_word_given_spam\n",
    "\n",
    "    n_word_given_ham = ham_msg[word].sum()\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + (alpha * n_vocabulary))\n",
    "    p_ham_words[word] = p_word_given_ham\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we check the updated dictionaries, we can see the values have updated to reflect the probability of each word given spam or non-spam."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08709501522 1.537988311288834e-05\n",
      "received 4.6139649338665025e-05\n",
      "book 0.00019993848046754843\n",
      "shorter 4.6139649338665025e-05\n",
      "adult 3.075976622577668e-05\n"
     ]
    }
   ],
   "source": [
    "for idx, (k, v) in enumerate(p_ham_words.items()):\n",
    "    if idx == 5: break\n",
    "    print(k, v)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classifying A New Message\n",
    "Now that we've calculated all the constants and parameters we need, we can start creating the spam filter. The spam filter can be understood as a function that:\n",
    "- Takes in as input a new message (w1, w2, ..., wn)\n",
    "- Calculates P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn)\n",
    "- Compares the values of P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn), and:\n",
    "    - If P(Ham|w1, w2, ..., wn) > P(Spam|w1, w2, ..., wn), then the message is classified as ham.\n",
    "    - If P(Ham|w1, w2, ..., wn) < P(Spam|w1, w2, ..., wn), then the message is classified as spam.\n",
    "    - If P(Ham|w1, w2, ..., wn) = P(Spam|w1, w2, ..., wn), then the algorithm may request human help."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "\n",
    "    # Clean message string\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    # calculate probability given message\n",
    "    for word in message:\n",
    "        if word in p_ham_words:\n",
    "            p_ham_given_message *= p_ham_words[word]\n",
    "        if word in p_spam_words:\n",
    "            p_spam_given_message *= p_spam_words[word]\n",
    "\n",
    "    # print probability value for message\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    # Classify message based on probability values\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal probabilities, have a human classify this!')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's test the function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Measuring the Spam Filter's Accuracy\n",
    "We've created a spam filter classified two new messages. We'll now try to determine how well the spam filter does on our test set of 1,114 messages. The algorithm will output a classification label for every message in our test set, which we'll be able to compare with the actual label (given by a human). Note that, in training, our algorithm didn't see these 1,114 messages, so every message in the test set is practically new from the perspective of the algorithm.\n",
    "\n",
    "Let's update the classify() function to return the labels instead of printing them."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in p_ham_words:\n",
    "            p_ham_given_message *= p_ham_words[word]\n",
    "        if word in p_spam_words:\n",
    "            p_spam_given_message *= p_spam_words[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we've updated our function, let's use it to create a new column in our test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "  Label                                                SMS predicted\n0   ham          later i guess  i needa do mcat study too        ham\n1   ham             but i haf enuff space got like 4 mb          ham\n2  spam  had your mobile 10 mths  update to latest oran...      spam\n3   ham  all sounds good  fingers   makes it difficult ...       ham\n4   ham  all done  all handed in  don t know if mega sh...       ham",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label</th>\n      <th>SMS</th>\n      <th>predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>later i guess  i needa do mcat study too</td>\n      <td>ham</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>but i haf enuff space got like 4 mb</td>\n      <td>ham</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>had your mobile 10 mths  update to latest oran...</td>\n      <td>spam</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>all sounds good  fingers   makes it difficult ...</td>\n      <td>ham</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>all done  all handed in  don t know if mega sh...</td>\n      <td>ham</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's compare the predicted values with the actual values to measure how good our spam filter is with classifying new messages. To make the measurement, we'll use accuracy as a metric:\n",
    "Accuracy = number of correctly classified messages / total number of classified messages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9874326750448833"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test_set)\n",
    "for index, row in test_set.iterrows():\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our accuracy metric shows that the algorithm is 99% accurate, which is well above our goal accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Next Steps\n",
    "Here's a few next steps:\n",
    "- Isolate the 14 messages that were classified incorrectly and try to figure out why the algorithm reached the wrong conclusions.\n",
    "- Make the filtering process more complex by making the algorithm sensitive to letter case."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
